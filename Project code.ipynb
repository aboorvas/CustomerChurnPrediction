{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Telco-Customer-Churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Churn is the target variable. Rest all are the predictor variables. However, the data types of almost all the variables are not appropriate. Hence, they all needs to be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pd.to_numeric function gave a string coercing error. Seemed like the total charges column had 11 blank values with a space in the cell. Therefore, it didn't even got identified as nulls. Those 11 records were manually made as nulls in the excel file. And then, the conversion function was applied to the variables.\n",
    "\n",
    "#### It was more appropriate to convert most of the predictor variables except TotalCharges,MonthlyCharges and tenure to category data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> Data type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\"customerID\":'category',\n",
    " \"gender\":'category',\n",
    " \"SeniorCitizen\":'category',\n",
    " \"Partner\":'category',\n",
    " \"Dependents\":'category',\n",
    " \"PhoneService\":'category',\n",
    " \"MultipleLines\":'category',\n",
    " \"InternetService\":'category',\n",
    " \"OnlineSecurity\":'category',\n",
    " \"OnlineBackup\":'category',\n",
    " \"DeviceProtection\":'category',\n",
    " \"TechSupport\":'category',\n",
    " \"StreamingTV\":'category',\n",
    " \"StreamingMovies\":'category',\n",
    " \"Contract\":'category',\n",
    " \"PaperlessBilling\":'category',\n",
    " \"PaymentMethod\":'category',\n",
    " \"Churn\":'category'})\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ->Null Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The total charges column has 11 nulls. This is a very small proportion of the total. Therefore, these records could be dropped or imputed using the mean value. We have done mean imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TotalCharges.fillna(df.TotalCharges.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ->Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=[\"MonthlyCharges\",\"TotalCharges\",\"tenure\"]\n",
    "num_df = df[numerical_features]\n",
    "num_df.describe()\n",
    "\n",
    "q1=num_df.quantile(0.25)\n",
    "q3=num_df.quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "IQR\n",
    "\n",
    "((num_df< (q1-(1.5*IQR))) | (num_df> (q3+(1.5*IQR)))).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### No outliers are present in the numerical columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> Factors of Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We could look into the unique records of each of the columns. \n",
    "##### This would give us an idea about the type of variables (Binary categorical predictors ,Multiple value categorical predictors,Numerical Predictors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(f\"Count of Unique {i}:{df[i].nunique()}\\n\")\n",
    "    print(f\"{df[i].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By looking at the previous output we could see that there are 6 binary categorical predictors excluding the Churn variable(Target Variable). Apart from that there are 10 multiple value categorical predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['category']).columns\n",
    "continous_columns = df.select_dtypes(exclude=['category']).columns\n",
    "\n",
    "print(continous_columns)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df[categorical_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('Correlation heatmap of categorical variables')\n",
    "sns.heatmap(df_corr.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "df_cont = df[continous_columns]\n",
    "plt.title('Correlation heatmap of numerical variables')\n",
    "sns.heatmap(df_cont.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> Target variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(df,column):    \n",
    "    ax = sns.countplot(y=column, data=df)\n",
    "    plt.title('Distribution of classes')\n",
    "    plt.xlabel('Number of Axles')\n",
    "    total = len(df[column])\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n",
    "        x = p.get_x() + p.get_width() + 0.02\n",
    "        y = p.get_y() + p.get_height()/2\n",
    "        ax.annotate(percentage, (x, y))\n",
    "    plt.show()  \n",
    "bar_plot(df, \"Churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We see that there is a class imbalance in the target variable. The success class Churn = Yes holds only 26.5 % of the total share.\n",
    "##### Undersampling or Over Sampling has to be done to balance the dataset before training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> Binary Categorical  variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 7), sharey=True)\n",
    "sns.countplot(x=\"gender\", data=df, ax=axes[0,0])\n",
    "sns.countplot(x=\"SeniorCitizen\", data=df, ax=axes[0,1])\n",
    "sns.countplot(x=\"Partner\", data=df, ax=axes[0,2])\n",
    "sns.countplot(x=\"Dependents\", data=df, ax=axes[1,0])\n",
    "sns.countplot(x=\"PhoneService\", data=df, ax=axes[1,1])\n",
    "sns.countplot(x=\"PaperlessBilling\", data=df, ax=axes[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There exists a little bit of class imbalance in the dependents variable. And a huge class imbalance exists in the senior citizen and phone service variables.\n",
    "\n",
    "##### We cannot come to any conclusion about the impact of these imbalance on the target variable. However we could analyse the target variable with each of these binary categorical variables. That could throw some light on the underlying insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We encode the values with 1 and 0, so that we could apply some math on these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ***********************************Label Encoding************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_numeric = {'Yes':1, 'No':0}\n",
    "df.Churn.replace(churn_numeric, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns \n",
    "binary_cat_cols = [] \n",
    "for col in columns:\n",
    "    if df[col].value_counts().shape[0] == 2:\n",
    "        binary_cat_cols.append(col)\n",
    "        \n",
    "binary_cat_cols=binary_cat_cols[0:6]\n",
    "\n",
    "for i in binary_cat_cols:\n",
    "    print(df[[i,'Churn']].groupby([i]).mean())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The type of gender doesn't seem to play a huge role in churning since the churn rate is the same for both gender.\n",
    "##### The PhoneService variable plays a tiny role in determining churning since there is only a small difference in churn rate between the factors. \n",
    "##### Rest all the Binary Categorical variables like SeniorCitizen, Partner, Dependents, PaperlessBilling impacts Churning considerably.\n",
    "\n",
    "##### Therefore, gender and Phone service variable could be removed from our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> Multiple categorical variable analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Internet Service variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"InternetService\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Most of them seem to have Fiber optic connection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['InternetService','Churn']].groupby('InternetService').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We see that most of them from the fiber optic connection have churned. There may be numerous resons for this. \n",
    "##### However, we could do analysis using the data available. We could check if the fiber optic connection is costly, which has lead to churning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['InternetService','MonthlyCharges']].groupby('InternetService').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YES!!!! Cost associated with fiber optic seems high. This could be a reason for churning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 7), sharey=True)\n",
    "sns.countplot(x=\"StreamingTV\", data=df, ax=axes[0,0])\n",
    "sns.countplot(x=\"StreamingMovies\", data=df, ax=axes[0,1])\n",
    "sns.countplot(x=\"OnlineSecurity\", data=df, ax=axes[0,2])\n",
    "sns.countplot(x=\"OnlineBackup\", data=df, ax=axes[1,0])\n",
    "sns.countplot(x=\"DeviceProtection\", data=df, ax=axes[1,1])\n",
    "sns.countplot(x=\"TechSupport\", data=df, ax=axes[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There exists no class imbalance among each of these predictors. As a next step, their impact on target variable could be analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Internet_cat_cols=['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport',\n",
    "                   'StreamingTV','StreamingMovies']\n",
    "\n",
    "for i in Internet_cat_cols:\n",
    "    print(df[[i,'Churn']].groupby([i]).mean())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Streaming TV and Streaming Movies exhibits almost  same splitup in determining churning. Similar case exists with Online security, Tech support and with Online backup, Device Protection. These pairs  could be correlated and could lead to multi collinearity. By analyzing the correlation analysis we did above, we find that their corralation is not more than 0.9. Therefore, We could keep any one of them if needed or include both in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Phone service variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PhoneService.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MultipleLines.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The yes and no value from the Phoneservice variable is accomodated by default within the Multiple Lines variable. Therefore, we could ignore the  Phone service variable and use the Multiple lines variable henceforth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['MultipleLines','Churn']].groupby('MultipleLines').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Each of the factors almost has the same rate of churning. Therefore, Including this variable in training the model would not do much help.\n",
    "##### Since we have already decided to drop phone service variable, we could keep this variable hoping that it adds some value to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contract Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x=\"Contract\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There exists more number of month to month contract customers. Usually, They have the highest possibility to churn because they can leave whenever they wish by the month end. Others have to wait for year long contract to end. We analyse if this hypothesis is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Contract','Churn']].groupby('Contract').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YES!!! MONTH TO MONTH CONTRACT CUSTOMERS HAVE THE HIGHEST CHURN RATE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Payment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x=\"PaymentMethod\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are more number of electronic check payment customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['PaymentMethod','Churn']].groupby('PaymentMethod').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Surprisingly, the payment method which has the most number of customers is associated with the most number of churning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> Numerical variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(12, 7))\n",
    "sns.histplot(x= df[\"tenure\"], ax=axes[0])\n",
    "sns.histplot(x= df[\"MonthlyCharges\"], ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MORE NUMBER OF CUSTOMERS LIE ON BOTH THE ENDS OF THE TENURE. We could say that many are new customers and they leave the contract soon. Also few customers stay for a long term.  The distribution drops in the middle portion. The same trend is seen in the distribution of monthly charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['tenure','MonthlyCharges','Churn']].groupby('Churn').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tenure is high for the people who don't churn and Monthly charges are low for the people who don't churn. These two variales have some effect on the churn rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Contract','tenure']].groupby('Contract').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tenure has some positive correlation with contract. We could use either one of these variables while training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## -> RESULTS\n",
    "\n",
    "### We have decided to drop the following predictors after EDA.\n",
    "\n",
    "##### 1. Customer ID\n",
    "##### 2. Gender\n",
    "##### 3. Contract\n",
    "##### 4. Total Charges\n",
    "##### 5. Phone Service\n",
    "\n",
    "### Reason:\n",
    "##### 1. It is logically inappropriate to use customer ID to predict Customer churn.\n",
    "##### 2. Gender had the same proportion split up for males and females in the number of churned customers. Therefore, Gender hasn't played a role in causing customer churn.\n",
    "##### 3. When we analysed the Contract and tenure together, we found that  customers with long term contract stays for more tenure and those with short term contracts stay for short tenure. They seemed positively correlated. Therefore, we remove it to avoid redundancy.\n",
    "##### 4. On exploring the dataset, we found that total charges was proportional to the product of tenure and monthly charges. Therefore, we remove it to avoid redundancy.\n",
    "##### 5. The data in the phone service column is duplicated in the multiple phone service column along with an extra factor. Therefore, it is best to use the predictor with more detail. Therefore, we drop the phone service variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['customerID','gender','Contract',\n",
    "         'TotalCharges','PhoneService'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> Encoding (One Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.get_dummies(df, \n",
    "                     columns=['SeniorCitizen', 'Partner', 'Dependents',\n",
    "                              'MultipleLines','InternetService','OnlineSecurity',\n",
    "                              'OnlineBackup','DeviceProtection','TechSupport', \n",
    "                              'StreamingTV','StreamingMovies', 'PaperlessBilling', \n",
    "                              'PaymentMethod'],drop_first=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale=MinMaxScaler()\n",
    "df1['MonthlyCharges']=scale.fit_transform(df1[['MonthlyCharges']])\n",
    "df1['tenure']=scale.fit_transform(df1[['tenure']])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "## -> Stratified Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df1.drop(['Churn'], axis=1) #features (independent variables)\n",
    "y = df1['Churn'] #target (dependent variable)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                    stratify= y, random_state=42)\n",
    "print(y_train.value_counts(normalize= True))\n",
    "print(y_test.value_counts(normalize= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> Over Sampling the train set (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "smotenc = SMOTENC([2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],\n",
    "                  random_state = 101)\n",
    "X_oversample_train, y_oversample_train = smotenc.fit_resample(X_train, y_train)\n",
    "print(y_oversample_train.value_counts(normalize= True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> MODEL 1 : RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "clf_forest = RandomForestClassifier(n_estimators=100, max_depth=10,random_state=1)\n",
    "clf_forest.fit(X_train,y_train)\n",
    "\n",
    "pred = clf_forest.predict(X_train)\n",
    "print('Training set accuracy on non - over sampled data : ',accuracy_score(y_train, pred))\n",
    "\n",
    "pred_test = clf_forest.predict(X_test)\n",
    "print('Test set accuracy on non - over sampled data : ',accuracy_score(y_test, pred_test))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(classification_report(y_test,clf_forest.predict(X_test)))\n",
    "\n",
    "print('\\nConfusion matrix before over sampling:')\n",
    "print(confusion_matrix(y_test, pred_test))\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "plt.clf()\n",
    "cm=confusion_matrix(y_test, pred_test)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVER SAMPLED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_forest = RandomForestClassifier(n_estimators=100, max_depth=10,random_state=1)\n",
    "clf_forest.fit(X_oversample_train,y_oversample_train)\n",
    "\n",
    "pred = clf_forest.predict(X_oversample_train)\n",
    "print('Training set accuracy on over sampled data : ',accuracy_score(y_oversample_train, pred))\n",
    "\n",
    "pred_test = clf_forest.predict(X_test)\n",
    "print('Test set accuracy on non - over sampled data : ',accuracy_score(y_test, pred_test))\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(y_test,clf_forest.predict(X_test)))\n",
    "\n",
    "\n",
    "print('\\nConfusion matrix after over sampling:')\n",
    "print(confusion_matrix(y_test, pred_test))\n",
    "\n",
    "##########################################################\n",
    "\n",
    "plt.clf()\n",
    "cm=confusion_matrix(y_test, pred_test)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Oversample Vs Original Data Results: \n",
    "\n",
    "#### Sensitivity for class 1 in Oversampled Data is 0.70 and Original Data is 0.52.\n",
    "#### Hence we can conclude that after Oversampling we have got a better classification model with 70% sensitivity value, although the accurancy has gone down.\n",
    "#### Our motive is to identify only the churing customers(class 1), therefore we need a better Sensitivity value but not the Accuracy and our motive has been achieved by Oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "probs = clf_forest.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('RANDOM FOREST ROC CURVE')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_rf = {'n_estimators' : [1000,1100,1200,1300,1400],\n",
    "                'max_depth' : np.arange(12,30,2)}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1,bootstrap=True)\n",
    "rf_random_grid = GridSearchCV(rf,param_grid_rf,cv=5,verbose=1,scoring='recall')\n",
    "\n",
    "rf_random_grid.fit(X_oversample_train,y_oversample_train)\n",
    "\n",
    "y_pred_rf_tuned = rf_random_grid.predict(X_test)\n",
    "y_pred_rf_tuned_prob = rf_random_grid.predict_proba(X_test)\n",
    "\n",
    "print('Best Parametrs : ', rf_random_grid.best_params_)\n",
    "print('Best Score : ', rf_random_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(y_test,y_pred_rf_tuned))\n",
    "\n",
    "\n",
    "print('\\nConfusion matrix after over sampling and hyper parameter tuning:')\n",
    "print(confusion_matrix(y_test, y_pred_rf_tuned))\n",
    "\n",
    "##########################################################\n",
    "\n",
    "plt.clf()\n",
    "cm=confusion_matrix(y_test, y_pred_rf_tuned)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()\n",
    "\n",
    "#############################################################\n",
    "\n",
    "\n",
    "preds = y_pred_rf_tuned_prob[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('RANDOM FOREST ROC CURVE ')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> MODEL 2 : LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "logreg_pred = logreg.predict(X_train)\n",
    "print('Training set accuracy on Non - over sampled data : ',accuracy_score(y_train, logreg_pred))\n",
    "\n",
    "logreg_pred_test = logreg.predict(X_test)\n",
    "print('Test set accuracy on Non - over sampled data : ',accuracy_score(y_test, logreg_pred_test))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(classification_report(y_test,logreg.predict(X_test)))\n",
    "\n",
    "print('Confusion matrix before over sampling:')\n",
    "cm_logreg = confusion_matrix(y_test, logreg_pred_test)\n",
    "print(cm_logreg)\n",
    "\n",
    "############################################################################\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm_logreg, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm_logreg[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVER SAMPLED DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_oversample_train,y_oversample_train)\n",
    "\n",
    "logreg_pred = logreg.predict(X_oversample_train)\n",
    "print('Training set accuracy on over sampled data : ',accuracy_score(y_oversample_train, logreg_pred))\n",
    "\n",
    "logreg_pred_test = logreg.predict(X_test)\n",
    "print('Test set accuracy on Non - over sampled data : ',accuracy_score(y_test, logreg_pred_test))\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(y_test,logreg.predict(X_test)))\n",
    "\n",
    "print('Confusion matrix after over sampling:')\n",
    "cm_logreg = confusion_matrix(y_test, logreg_pred_test)\n",
    "print(cm_logreg)\n",
    "\n",
    "############################################################################\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm_logreg, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm_logreg[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Oversample Vs Original Data Results: \n",
    "\n",
    "#### Sensitivity for class 1 in Oversampled Data is 0.72 and Original Data is 0.51.\n",
    "#### Hence we can conclude that after Oversampling we have got a better classification model with 72% sensitivity value, although the accurancy has gone down.\n",
    "#### Our motive is to identify only the churing customers(class 1), therefore we need a better Sensitivity value but not the Accuracy and our motive has been achieved by Oversampling.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('LOGISTIC REGRESSION ROC CURVE')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid_L1 = {'penalty' : ['l1','l2'], 'C' : np.arange(.1,5,.1)}\n",
    "\n",
    "param_grid = [{'C': [0.001, 0.1, 1.0], 'class_weight': [None, 'balanced'],\n",
    "               'solver': ['newton-cg', 'lbfgs','liblinear', 'sag', 'saga']}]\n",
    "\n",
    "logreg_tuned = LogisticRegression(max_iter=1000)\n",
    "logreg_tuned_gs = GridSearchCV(logreg_tuned,param_grid,cv=5,verbose=1,scoring='recall')\n",
    "\n",
    "logreg_tuned_gs.fit(X_oversample_train,y_oversample_train)\n",
    "\n",
    "y_pred_logreg_tuned = logreg_tuned_gs.predict(X_test)\n",
    "y_pred_logreg_tuned_prob = logreg_tuned_gs.predict_proba(X_test)\n",
    "\n",
    "print('Best Parameters : ', logreg_tuned_gs.best_params_)\n",
    "\n",
    "print(classification_report(y_test,y_pred_logreg_tuned))\n",
    "\n",
    "\n",
    "print('\\nConfusion matrix after over sampling and hyper parameter tuning:')\n",
    "print(confusion_matrix(y_test, y_pred_logreg_tuned))\n",
    "\n",
    "##########################################################\n",
    "\n",
    "plt.clf()\n",
    "cm=confusion_matrix(y_test, y_pred_logreg_tuned)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()\n",
    "\n",
    "#############################################################\n",
    "\n",
    "preds = y_pred_logreg_tuned_prob[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('logistic regression ROC CURVE ')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> MODEL 3 : SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel='rbf', probability = True)\n",
    "SVM.fit(X_train,y_train)\n",
    "\n",
    "svm_pred = SVM.predict(X_train)\n",
    "print('Training set accuracy on Non - over sampled data : ',accuracy_score(y_train, svm_pred))\n",
    "\n",
    "svm_pred_test = SVM.predict(X_test)\n",
    "print('Test set accuracy on Non - over sampled data : ',accuracy_score(y_test, svm_pred_test))\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(y_test,SVM.predict(X_test)))\n",
    "\n",
    "print('Confusion matrix before over sampling : ')\n",
    "cm_svm = confusion_matrix(y_test, svm_pred_test)\n",
    "print(cm_svm)\n",
    "\n",
    "############################################################\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm_svm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm_svm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVER SAMPLED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(kernel='rbf', probability = True)\n",
    "SVM.fit(X_oversample_train,y_oversample_train)\n",
    "\n",
    "svm_pred = SVM.predict(X_oversample_train)\n",
    "print('Training set accuracy on over sampled data : ',accuracy_score(y_oversample_train, svm_pred))\n",
    "\n",
    "svm_pred_test = SVM.predict(X_test)\n",
    "print('Test set accuracy on Non - over sampled data : ',accuracy_score(y_test, svm_pred_test))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(classification_report(y_test,SVM.predict(X_test)))\n",
    "\n",
    "print('Confusion matrix before over sampling : ')\n",
    "cm_svm = confusion_matrix(y_test, svm_pred_test)\n",
    "print(cm_svm)\n",
    "\n",
    "############################################################\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm_svm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm_svm[i][j]))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Oversample Vs Original Data Results: \n",
    "\n",
    "#### Sensitivity for class 1 in Oversampled Data is 0.69 and Original Data is 0.46.\n",
    "#### Hence we can conclude that after Oversampling we have got a better classification model with 69% sensitivity value, although the accurancy has gone down.\n",
    "#### Our motive is to identify only the churing customers(class 1), therefore we need a better Sensitivity value but not the Accuracy and our motive has been achieved by Oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "probs = SVM.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('SVM ROC CURVE')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = [{'C':[0.1,1,100,1000],'kernel':['rbf'],'degree':[1,2,3,4,5,6],\n",
    "            'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}]\n",
    "\n",
    "svm_tuned = SVC(probability = True)\n",
    "svm_tuned_gs = GridSearchCV(svm_tuned,param_grid,cv=5,verbose=1,scoring='recall')\n",
    "\n",
    "svm_tuned_gs.fit(X_oversample_train,y_oversample_train)\n",
    "\n",
    "y_pred_svm_tuned = svm_tuned_gs.predict(X_test)\n",
    "y_pred_svm_tuned_prob = svm_tuned_gs.predict_proba(X_test)\n",
    "\n",
    "print('Best Parameters : ', svm_tuned_gs.best_params_)\n",
    "\n",
    "print(classification_report(y_test,y_pred_svm_tuned))\n",
    "\n",
    "\n",
    "print('\\nConfusion matrix after over sampling and hyper parameter tuning:')\n",
    "print(confusion_matrix(y_test, y_pred_svm_tuned))\n",
    "\n",
    "##########################################################\n",
    "\n",
    "plt.clf()\n",
    "cm=confusion_matrix(y_test, y_pred_svm_tuned)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()\n",
    "\n",
    "#############################################################\n",
    "\n",
    "preds = y_pred_svm_tuned_prob[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('logistic regression ROC CURVE ')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -> MODEL 4 : KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.get_dummies(df, \n",
    "                     columns=['SeniorCitizen', 'Partner', 'Dependents',\n",
    "                              'MultipleLines','InternetService','OnlineSecurity',\n",
    "                              'OnlineBackup','DeviceProtection','TechSupport', \n",
    "                              'StreamingTV','StreamingMovies', 'PaperlessBilling', \n",
    "                              'PaymentMethod'],drop_first=False)\n",
    "\n",
    "#numeric_tags = {'Yes':1, 'No':0}\n",
    "#df1.Churn.replace(numeric_tags, inplace=True)\n",
    "###########################################################\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale=MinMaxScaler()\n",
    "df1['MonthlyCharges']=scale.fit_transform(df1[['MonthlyCharges']])\n",
    "df1['tenure']=scale.fit_transform(df1[['tenure']])\n",
    "##################################################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df1.drop(['Churn'], axis=1) #features (independent variables)\n",
    "y = df1['Churn'] #target (dependent variable)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                    stratify= y, random_state=42)\n",
    "print(y_train.value_counts(normalize= True))\n",
    "print(y_test.value_counts(normalize= True))\n",
    "####################################################################\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "smotenc = SMOTENC([2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,\n",
    "                  30,31,32,33,34,35,36,37],\n",
    "                  random_state = 101)\n",
    "X_oversample_train, y_oversample_train = smotenc.fit_resample(X_train, y_train)\n",
    "print(y_oversample_train.value_counts(normalize= True))\n",
    "####################################################################\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "knn_pred = knn.predict(X_train)\n",
    "print('Training set accuracy on non-oversampled data : ',accuracy_score(y_train, knn_pred))\n",
    "\n",
    "knn_pred_test = knn.predict(X_test)\n",
    "print('Test set accuracy on non-oversampled data : ',accuracy_score(y_test, knn_pred_test))\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(y_test,knn.predict(X_test)))\n",
    "print('\\n')\n",
    "\n",
    "cm_knn = confusion_matrix(y_test, knn_pred_test)\n",
    "print('Confusion Matrix before oversampling :')\n",
    "print(cm_knn)\n",
    "\n",
    "#################################################################\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm_knn, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm_knn[i][j]))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVER SAMPLED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_oversample_train,y_oversample_train)\n",
    "\n",
    "knn_pred = knn.predict(X_oversample_train)\n",
    "print('Training set accuracy on oversampled data : ',accuracy_score(y_oversample_train, knn_pred))\n",
    "\n",
    "knn_pred_test = knn.predict(X_test)\n",
    "print('Test set accuracy on non-oversampled data : ',accuracy_score(y_test, knn_pred_test))\n",
    "\n",
    "\n",
    "print(classification_report(y_test,knn.predict(X_test)))\n",
    "print('\\n')\n",
    "\n",
    "print('Confusion matrix after oversampliing :')\n",
    "cm_knn = confusion_matrix(y_test, knn_pred_test)\n",
    "print(cm_knn)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm_knn, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm_knn[i][j]))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN - Oversample Vs Original Data Results: \n",
    "\n",
    "#### Sensitivity for class 1 in Oversampled Data is 0.68 and Original Data is 0.46.\n",
    "#### Hence we can conclude that after Oversampling we have got a better classification model with 68% sensitivity value, although the accurancy has gone down.\n",
    "#### Our motive is to identify only the churing customers(class 1), therefore we need a better Sensitivity value but not the Accuracy and our motive has been achieved by Oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "probs = knn.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title('KNN ROC CURVE')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors':np.arange(1,30)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn,param_grid,cv=5,verbose=1,scoring='recall')\n",
    "knn_cv.fit(X_oversample_train,y_oversample_train)\n",
    "\n",
    "y_pred_knn_tuned = knn_cv.predict(X_test)\n",
    "y_pred_knn_tuned_prob = knn_cv.predict_proba(X_test)\n",
    "\n",
    "print('Best Parameters : ',knn_cv.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_knn_tuned))\n",
    "\n",
    "\n",
    "print('\\nConfusion matrix after over sampling and hyper parameter tuning:')\n",
    "print(confusion_matrix(y_test, y_pred_knn_tuned))\n",
    "\n",
    "##########################################################\n",
    "\n",
    "plt.clf()\n",
    "cm=confusion_matrix(y_test, y_pred_knn_tuned)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
    "classNames = ['0','1']\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()\n",
    "#############################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -> COST CALCULATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost calculation -> Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_predict\n",
    "\n",
    "logistic_gain = []\n",
    "i_vals = []\n",
    "cost = []\n",
    "savings = []\n",
    "i = .01\n",
    "\n",
    "logreg_tuned_gs.fit(X_oversample_train,y_oversample_train)\n",
    "pred = logreg_tuned_gs.predict(X_test)\n",
    "\n",
    "for i in np.linspace(0, 1, 101):\n",
    "    folds = KFold(n_splits=5, shuffle=True)\n",
    "    probs = cross_val_predict(logreg_tuned_gs.best_estimator_, X_train, y_train, cv=folds, \n",
    "                              method='predict_proba', n_jobs=-1)\n",
    "    probs = pd.DataFrame(probs)\n",
    "    new_pred = probs[1].apply(lambda x: 1 if x > i else 0)\n",
    "    conf = confusion_matrix(y_train, new_pred)\n",
    "\n",
    "    total_cost = (conf[0][1] * 100) + (conf[1][1] * 100) + (conf[1][0] * 500)\n",
    "    total_savings = conf[1][1] * 500\n",
    "\n",
    "    net_gain = total_savings - total_cost\n",
    "    logistic_gain.append(net_gain)\n",
    "    i_vals.append(i)\n",
    "    cost.append(total_cost)\n",
    "    savings.append(total_savings)\n",
    "\n",
    "print(f'Max net gain = {max(logistic_gain)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.plot(i_vals, logistic_gain, label='Logistic Regression', color='green', lw=2)\n",
    "ax.axhline(y=0, color='black')\n",
    "ax.set_xlabel('Probability Threshold', fontsize=16, labelpad=10)\n",
    "ax.set_ylabel('$ Saved', rotation=90, fontsize=16, labelpad=10)\n",
    "ax.set_yticklabels(['-100k', '0', '100k', '200k', '300k'], fontsize=12)\n",
    "ax.set_xticklabels(['0', '0.1', '0.2', '0.3', '0.4', '0.5'], fontsize=12)\n",
    "ax.set_yticks([-100000, 0, 100000, 200000, 300000])\n",
    "ax.set_xbound(lower=0, upper=0.5)\n",
    "ax.set_ybound(lower=-100000, upper=300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost calculation -> KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_gain = []\n",
    "i_vals = []\n",
    "cost = []\n",
    "savings = []\n",
    "i = .01\n",
    "\n",
    "knn_cv.fit(X_oversample_train,y_oversample_train)\n",
    "pred = knn_cv.predict(X_test)\n",
    "\n",
    "for i in np.linspace(0, 1, 101):\n",
    "    folds = KFold(n_splits=5, shuffle=True)\n",
    "    probs = cross_val_predict(knn_cv.best_estimator_, X_train, y_train, cv=folds, \n",
    "                              method='predict_proba', n_jobs=-1)\n",
    "    probs = pd.DataFrame(probs)\n",
    "    new_pred = probs[1].apply(lambda x: 1 if x > i else 0)\n",
    "    conf = confusion_matrix(y_train, new_pred)\n",
    "\n",
    "    total_cost = (conf[0][1] * 100) + (conf[1][1] * 100) + (conf[1][0] * 500)\n",
    "    total_savings = conf[1][1] * 500\n",
    "\n",
    "    net_gain = total_savings - total_cost\n",
    "    logistic_gain.append(net_gain)\n",
    "    i_vals.append(i)\n",
    "    cost.append(total_cost)\n",
    "    savings.append(total_savings)\n",
    "\n",
    "print(f'Max net gain = {max(logistic_gain)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.plot(i_vals, logistic_gain, label='KNN', color='green', lw=2)\n",
    "ax.axhline(y=0, color='black')\n",
    "ax.set_xlabel('Probability Threshold', fontsize=16, labelpad=10)\n",
    "ax.set_ylabel('$ Saved', rotation=90, fontsize=16, labelpad=10)\n",
    "ax.set_yticklabels(['-100k', '0', '100k', '200k', '300k'], fontsize=12)\n",
    "ax.set_xticklabels(['0', '0.1', '0.2', '0.3', '0.4', '0.5'], fontsize=12)\n",
    "ax.set_yticks([-100000, 0, 100000, 200000, 300000])\n",
    "ax.set_xbound(lower=0, upper=0.5)\n",
    "ax.set_ybound(lower=-100000, upper=300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHEN WE THINK NO CUSTOMERS WILL CHURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_zeros = np.zeros(shape=(5634,))\n",
    "\n",
    "conf = confusion_matrix(y_train, new_pred_zeros)\n",
    "\n",
    "total_cost = (conf[0][1] * 100) + (conf[1][1] * 100) + conf[1][0] * 500\n",
    "total_savings = conf[1][1] * 500\n",
    "\n",
    "net_gain = total_savings - total_cost\n",
    "print(net_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHEN WE THINK ALL CUSTOMERS WILL CHURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_ones = np.ones(shape=(5634,))\n",
    "\n",
    "conf = confusion_matrix(y_train, new_pred_ones)\n",
    "\n",
    "total_cost = (conf[0][1] * 100) + (conf[1][1] * 100) + conf[1][0] * 500\n",
    "total_savings = conf[1][1] * 500\n",
    "\n",
    "net_gain = total_savings - total_cost\n",
    "print(net_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
